
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://github.com/aws-samples/easy-model-deployer/print_page/">
      
      
      
      
      <link rel="icon" href="https://s3.cn-north-1.amazonaws.com.cn/aws-assets-prod/libra-css/images/site/fav/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.5">
    
    
      
        <title>Print Site - Easy Model Deployer</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8608ea7d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/print-site-enum-headings1.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings2.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings3.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings4.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings5.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings6.css">
    
      <link rel="stylesheet" href="../css/print-site.css">
    
      <link rel="stylesheet" href="../css/print-site-material.css">
    
    <script>__md_scope=new URL("/aws-samples/easy-model-deployer/",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  
        <script type="text/javascript">
        document.addEventListener('DOMContentLoaded', function () {
            remove_material_navigation();remove_mkdocs_theme_navigation();generate_toc();
        })
        </script>
        </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#architecture" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Easy Model Deployer" class="md-header__button md-logo" aria-label="Easy Model Deployer" data-md-component="logo">
      
  <img src="https://s3.cn-north-1.amazonaws.com.cn/aws-assets-prod/libra-css/images/site/fav/favicon.ico" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Easy Model Deployer
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Print Site
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/easy-model-deployer/en/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/aws-samples/easy-model-deployer/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    aws-samples/easy-model-deployer
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../architecture/" class="md-tabs__link">
        
  
    
  
  Architecture

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../installation/" class="md-tabs__link">
        
  
    
  
  Installation

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../best_deployment_practices/" class="md-tabs__link">
        
  
    
  
  Best-Deployment-Practices

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../emd_client/" class="md-tabs__link">
        
  
    
  
  EMD-Client

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../langchain_interface/" class="md-tabs__link">
        
  
    
  
  Langchain-Interface

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../openai_compatiable/" class="md-tabs__link">
        
  
    
  
  OpenAI-Compatiable

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../supported_models/" class="md-tabs__link">
        
  
    
  
  Supported Model

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Easy Model Deployer" class="md-nav__button md-logo" aria-label="Easy Model Deployer" data-md-component="logo">
      
  <img src="https://s3.cn-north-1.amazonaws.com.cn/aws-assets-prod/libra-css/images/site/fav/favicon.ico" alt="logo">

    </a>
    Easy Model Deployer
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/aws-samples/easy-model-deployer/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    aws-samples/easy-model-deployer
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Architecture
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../best_deployment_practices/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Best-Deployment-Practices
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../emd_client/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EMD-Client
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain_interface/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Langchain-Interface
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../openai_compatiable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenAI-Compatiable
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../supported_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Model
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      1. Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      2. Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best_deployment_practices" class="md-nav__link">
    <span class="md-ellipsis">
      3. Best-Deployment-Practices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#emd_client" class="md-nav__link">
    <span class="md-ellipsis">
      4. EMD-Client
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain_interface" class="md-nav__link">
    <span class="md-ellipsis">
      5. Langchain-Interface
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openai_compatiable" class="md-nav__link">
    <span class="md-ellipsis">
      6. OpenAI-Compatiable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supported_models" class="md-nav__link">
    <span class="md-ellipsis">
      7. Supported Model
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<div id="print-site-page" class="print-site-enumerate-headings print-site-enumerate-figures">
        <section class="print-page">
            <div id="print-page-toc" data-toc-depth="3">
                <nav role='navigation' class='print-page-toc-nav'>
                <h1 class='print-page-toc-title'>Table of Contents</h1>
                </nav>
            </div>
        </section>
        <section class="print-page" id="architecture"><h1 id="architecture-architecture">Architecture</h1>
<p>Deploy models to the cloud with EMD will use the following components in Amazon Web Services:</p>
<p><img alt="alt text" src="../emd-architecture.png" /></p>
<ol>
<li>
<p>User/Client initiates model deployment task, triggering pipeline to start model building.</p>
</li>
<li>
<p>AWS CodeBuild constructs the large model using predefined configuration and publishes it to Amazon ECR.</p>
</li>
<li>
<p>AWS CloudFormation creates a model infrastructure stack based on user selection and deploys the model from ECR to AWS services (Amazon SageMaker, EC2, ECS).</p>
</li>
</ol></section><section class="print-page" id="installation"><h1 id="installation-installation">Installation</h1><h2 id="installation-guide">Installation Guide</h2>
<h3 id="installation-prerequisites">Prerequisites</h3>
<ul>
<li>Python 3.9 or higher</li>
<li>pip (Python package installer)</li>
</ul>
<h3 id="installation-setting-up-the-environment">Setting up the Environment</h3>
<ol>
<li>
<p>Create a virtual environment:
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>emd-env
</code></pre></div></p>
</li>
<li>
<p>Activate the virtual environment:
<div class="highlight"><pre><span></span><code><span class="nb">source</span><span class="w"> </span>emd-env/bin/activate
</code></pre></div></p>
</li>
<li>
<p>Install the required packages:
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>https://github.com/aws-samples/easy-model-deployer/releases/download/emd-0.7.1/emd-0.7.1-py3-none-any.whl
</code></pre></div></p>
</li>
</ol>
<h2 id="installation-deployment-parameters">Deployment parameters</h2>
<h3 id="installation--force-update-env-stack">--force-update-env-stack</h3>
<p>No additional <code>emd bootstrap</code> required for deployment. Because of other commands, status/destroy etc. require pre-bootstrapping. Therefore, it is recommended to run <code>emd bootstrap</code> separately after each upgrade.</p>
<h3 id="installation--extra-params">--extra-params</h3>
<p>Extra parameters passed to the model deployment. extra-params should be a Json object of dictionary format as follows:</p>
<p><div class="highlight"><pre><span></span><code><span class="p">{</span>

<span class="w">  </span><span class="nt">&quot;model_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;service_params&quot;</span><span class="p">:{</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;instance_params&quot;</span><span class="p">:{</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;engine_params&quot;</span><span class="p">:{</span>
<span class="w">      </span><span class="nt">&quot;cli_args&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;command line arguments of current engine&gt;&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;api_key&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;api key&gt;&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;framework_params&quot;</span><span class="p">:{</span>
<span class="w">      </span><span class="nt">&quot;uvicorn_log_level&quot;</span><span class="p">:</span><span class="s2">&quot;info&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;limit_concurrency&quot;</span><span class="p">:</span><span class="mi">200</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
To learn some practice examples, please refer to the <a href="#installation-docs-en-best_deployment_practices.md">Best Deployment Practices</a>.</p>
<h2 id="installation-local-deployment-on-the-ec2-instance">Local deployment on the ec2 instance</h2>
<p>This is suitable for deploying models using local GPU resources.</p>
<h3 id="installation-pre-requisites">Pre-requisites</h3>
<h4 id="installation-start-and-connect-to-ec2-instance">Start and connect to EC2 instance</h4>
<p>It is recommended to launch the instance using the AMI "<strong>Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.6 (Ubuntu 22.04)</strong>".</p>
<h3 id="installation-deploy-model-using-emd">Deploy model using EMD</h3>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>deploy<span class="w"> </span>--allow-local-deploy
</code></pre></div>
<p>There some EMD configuration sample settings for model deployment in the following two sections: <a href="#installation-non-reasoning-model-deployment-configuration">Non-reasoning Model deployment configuration</a> and <a href="#installation-reasoning-model-deployment-configuration">Reasoning Model deployment configuration</a>.
Wait for the model deployment to complete.</p>
<h4 id="installation-non-reasoning-model-deployment-configuration">Non-reasoning Model deployment configuration</h4>
<h5 id="installation-qwen25-72b-instruct-awq">Qwen2.5-72B-Instruct-AWQ</h5>
<div class="highlight"><pre><span></span><code>? Select the model series: qwen2.5
? Select the model name: Qwen2.5-72B-Instruct-AWQ
? Select the service for deployment: Local
? input the local gpu ids to deploy the model (e.g. 0,1,2): 0,1,2,3
? Select the inference engine to use: tgi
? (Optional) Additional deployment parameters (JSON string or local file path), you can skip by pressing Enter: {&quot;engine_params&quot;:{&quot;api_key&quot;:&quot;&lt;YOUR_API_KEY&gt;&quot;, &quot;default_cli_args&quot;: &quot;--max-total-tokens 30000 --max-concurrent-requests 30&quot;}}
</code></pre></div>
<h5 id="installation-llama-33-70b-instruct-awq">llama-3.3-70b-instruct-awq</h5>
<div class="highlight"><pre><span></span><code>? Select the model series: llama
? Select the model name: llama-3.3-70b-instruct-awq
? Select the service for deployment: Local
? input the local gpu ids to deploy the model (e.g. 0,1,2): 0,1,2,3
engine type: tgi
framework type: fastapi
? (Optional) Additional deployment parameters (JSON string or local file path), you can skip by pressing Enter: {&quot;engine_params&quot;:{&quot;api_key&quot;:&quot;&lt;YOUR_API_KEY&gt;&quot;, &quot;default_cli_args&quot;: &quot;--max-total-tokens 30000 --max-concurrent-requests 30&quot;}}
</code></pre></div>
<h4 id="installation-reasoning-model-deployment-configuration">Reasoning Model deployment configuration</h4>
<h5 id="installation-deepseek-r1-distill-qwen-32b">DeepSeek-R1-Distill-Qwen-32B</h5>
<div class="highlight"><pre><span></span><code>? Select the model series: deepseek reasoning model
? Select the model name: DeepSeek-R1-Distill-Qwen-32B
? Select the service for deployment: Local
? input the local gpu ids to deploy the model (e.g. 0,1,2): 0,1,2,3
engine type: vllm
framework type: fastapi
? (Optional) Additional deployment parameters (JSON string or local file path), you can skip by pressing Enter: {&quot;engine_params&quot;:{&quot;api_key&quot;:&quot;&lt;YOUR_API_KEY&gt;&quot;, &quot;default_cli_args&quot;: &quot;--enable-reasoning --reasoning-parser deepseek_r1 --max_model_len 16000 --disable-log-stats --chat-template emd/models/chat_templates/deepseek_r1_distill.jinja --max_num_seq 20 --gpu_memory_utilization 0.9&quot;}}
</code></pre></div>
<h5 id="installation-deepseek-r1-distill-llama-70b-awq">deepseek-r1-distill-llama-70b-awq</h5>
<div class="highlight"><pre><span></span><code>? Select the model series: deepseek reasoning model
? Select the model name: deepseek-r1-distill-llama-70b-awq
? Select the service for deployment: Local
? input the local gpu ids to deploy the model (e.g. 0,1,2): 0,1,2,3
? Select the inference engine to use: tgi
framework type: fastapi
? (Optional) Additional deployment parameters (JSON string or local file path), you can skip by pressing Enter: {&quot;engine_params&quot;:{&quot;api_key&quot;:&quot;&lt;YOUR_API_KEY&gt;&quot;, &quot;default_cli_args&quot;: &quot;--max-total-tokens 30000 --max-concurrent-requests 30&quot;}}
</code></pre></div>
<h2 id="installation-examples">Examples</h2></section><section class="print-page" id="best_deployment_practices"><h1 id="best_deployment_practices-best-deployment-practices">Best Deployment Practices</h1>
<p>This document provides examples of best practices for deploying models using EMD for various use cases.</p>
<h2 id="best_deployment_practices-famous-models">Famous Models</h2>
<h3 id="best_deployment_practices-mistral-small-series">Mistral Small Series</h3>
<div class="highlight"><pre><span></span><code>emd deploy --model-id Mistral-Small-3.1-24B-Instruct-2503 --instance-type g5.12xlarge --engine-type vllm --service-type sagemaker_realtime
</code></pre></div>
<h3 id="best_deployment_practices-gemma-3-series">Gemma 3 Series</h3>
<div class="highlight"><pre><span></span><code>emd deploy --model-id gemma-3-27b-it --instance-type g5.12xlarge --engine-type vllm --service-type sagemaker_realtime
</code></pre></div>
<h3 id="best_deployment_practices-qwen-series">Qwen Series</h3>
<h4 id="best_deployment_practices-qwen25-vl-32b-instruct">Qwen2.5-VL-32B-Instruct</h4>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>deploy<span class="w"> </span>--model-id<span class="w"> </span>Qwen2.5-VL-32B-Instruct<span class="w"> </span>--instance-type<span class="w"> </span>g5.12xlarge<span class="w"> </span>--engine-type<span class="w"> </span>vllm<span class="w"> </span>--service-type<span class="w"> </span>sagemaker_realtime
</code></pre></div>
<h4 id="best_deployment_practices-qwq-32b">QwQ-32B</h4>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>deploy<span class="w"> </span>--model-id<span class="w"> </span>QwQ-32B<span class="w"> </span>--instance-type<span class="w"> </span>g5.12xlarge<span class="w"> </span>--engine-type<span class="w"> </span>vllm<span class="w"> </span>--service-type<span class="w"> </span>sagemaker_realtime
</code></pre></div>
<h2 id="best_deployment_practices-deploying-to-specific-gpu-types">Deploying to Specific GPU Types</h2>
<p>Choosing the right GPU type is critical for optimal performance and cost-efficiency. Use the <code>--instance-type</code> parameter to specify the GPU instance.</p>
<h3 id="best_deployment_practices-example-deploying-qwen25-7b-on-g52xlarge">Example: Deploying Qwen2.5-7B on g5.2xlarge</h3>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>deploy<span class="w"> </span>--model-id<span class="w"> </span>Qwen2.5-7B-Instruct<span class="w"> </span>--instance-type<span class="w"> </span>g5.2xlarge<span class="w"> </span>--engine-type<span class="w"> </span>vllm<span class="w"> </span>--service-type<span class="w"> </span>sagemaker_realtime
</code></pre></div>
<h2 id="best_deployment_practices-achieving-longer-context-windows">Achieving Longer Context Windows</h2>
<p>To enable longer context windows, use the <code>--extra-params</code> option with engine-specific parameters.</p>
<h3 id="best_deployment_practices-example-deploying-model-with-16k-context-window">Example: Deploying model with 16k context window</h3>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>deploy<span class="w"> </span>--model-id<span class="w"> </span>Qwen2.5-7B-Instruct<span class="w"> </span>--instance-type<span class="w"> </span>g5.4xlarge<span class="w"> </span>--engine-type<span class="w"> </span>vllm<span class="w"> </span>--service-type<span class="w"> </span>sagemaker_realtime<span class="w"> </span>--extra-params<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">  &quot;engine_params&quot;: {</span>
<span class="s1">    &quot;vllm_cli_args&quot;: &quot;--max_model_len 16000 --max_num_seqs 4&quot;</span>
<span class="s1">  }</span>
<span class="s1">}&#39;</span>
</code></pre></div>
<h3 id="best_deployment_practices-example-deploying-model-on-g4dn-instance">Example: Deploying model on G4dn instance</h3>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>deploy<span class="w"> </span>--model-id<span class="w"> </span>Qwen2.5-14B-Instruct-AWQ<span class="w"> </span>--instance-type<span class="w"> </span>g4dn.2xlarge<span class="w"> </span>--engine-type<span class="w"> </span>vllm<span class="w"> </span>--service-type<span class="w"> </span>sagemaker_realtime<span class="w"> </span>--extra-params<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">  &quot;engine_params&quot;: {</span>
<span class="s1">    &quot;environment_variables&quot;: &quot;export VLLM_ATTENTION_BACKEND=XFORMERS &amp;&amp; export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True&quot;,</span>
<span class="s1">    &quot;default_cli_args&quot;: &quot; --chat-template emd/models/chat_templates/qwen_2d5_add_prefill_chat_template.jinja --max_model_len 12000 --max_num_seqs 10  --gpu_memory_utilization 0.95 --disable-log-stats --enable-auto-tool-choice --tool-call-parser hermes&quot;</span>
<span class="s1">  }</span>
<span class="s1">}&#39;</span>
</code></pre></div>
<h3 id="best_deployment_practices-example-customize-model-download-methods">Example: Customize model download methods</h3>
<ul>
<li>You can load models from different locations by addingappropriate values in the extra-params parameter</li>
<li>Load model from S3
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_params&quot;</span><span class="p">:{</span>
<span class="w">    </span><span class="nt">&quot;model_files_s3_path&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;S3_PATH&gt;&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></li>
<li>Load model from local path (only applicable for local deployment)
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">    </span><span class="nt">&quot;model_files_local_path&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;LOCAL_PATH&gt;&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></li>
<li>Skip downloading and uploading model files in codebuild, which will significantly reducedeployment time
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;need_prepare_model&quot;</span><span class="p">:</span><span class="kc">false</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></li>
<li>Specify the download source for model files
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_params&quot;</span><span class="p">:{</span>
<span class="w">    </span><span class="nt">&quot;model_files_download_source&quot;</span><span class="p">:</span><span class="s2">&quot;huggingface|modelscope|auto(default)&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></li>
<li>Specify the model ID on huggingface or modelscope
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;huggingface_model_id&quot;</span><span class="p">:</span><span class="s2">&quot;model id on huggingface&quot;</span><span class="p">,</span><span class="nt">&quot;modelscope_model_id&quot;</span><span class="p">:</span><span class="s2">&quot;model id on modelscope&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></li>
</ul>
<h2 id="best_deployment_practices-environmental-variables">Environmental variables</h2>
<ul>
<li><code>LOCAL_DEPLOY_PORT:</code> Local deployment port, default: <code>8080</code></li>
</ul>
<h2 id="best_deployment_practices-common-troubleshooting">Common Troubleshooting</h2>
<ul>
<li>If your deployment fails due to out-of-memory issues, try:</li>
<li>Using a larger instance type</li>
<li>Reducing max_model_len and max_num_seqs in the engine parameters</li>
<li>Setting a lower gpu_memory_utilization value (e.g., 0.8 instead of the default)</li>
</ul></section><section class="print-page" id="emd_client"><h1 id="emd_client-usse-emd-client-to-invoke-deployed-models">Usse EMD client to invoke deployed models</h1>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w"> </span>MODEL_ID<span class="w"> </span>MODEL_TAG<span class="w"> </span><span class="o">(</span>Optional<span class="o">)</span>
</code></pre></div>
<h2 id="emd_client-llm-models">LLM models</h2>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w">  </span>DeepSeek-R1-Distill-Qwen-7B
...
Invoking<span class="w"> </span>model<span class="w"> </span>DeepSeek-R1-Distill-Qwen-7B<span class="w"> </span>with<span class="w"> </span>tag<span class="w"> </span>dev
Write<span class="w"> </span>a<span class="w"> </span>prompt,<span class="w"> </span>press<span class="w"> </span>Enter<span class="w"> </span>to<span class="w"> </span>generate<span class="w"> </span>a<span class="w"> </span>response<span class="w"> </span><span class="o">(</span>Ctrl+C<span class="w"> </span>to<span class="w"> </span>abort<span class="o">)</span>,
User:<span class="w"> </span>how<span class="w"> </span>to<span class="w"> </span>solve<span class="w"> </span>the<span class="w"> </span>problem<span class="w"> </span>of<span class="w"> </span>making<span class="w"> </span>more<span class="w"> </span>profit
Assistant:&lt;think&gt;

Okay,<span class="w"> </span>so<span class="w"> </span>I<span class="w"> </span>need<span class="w"> </span>to<span class="w"> </span>figure<span class="w"> </span>out<span class="w"> </span>how<span class="w"> </span>to<span class="w"> </span>make<span class="w"> </span>more<span class="w"> </span>profit.<span class="w"> </span>Profit<span class="w"> </span>is<span class="w"> </span>basically<span class="w"> </span>the<span class="w"> </span>money<span class="w"> </span>left<span class="w"> </span>after<span class="w"> </span>subtracting<span class="w"> </span>costs<span class="w"> </span>from<span class="w"> </span>revenue,<span class="w"> </span>right?<span class="w"> </span>So,<span class="w"> </span>increasing<span class="w"> </span>profit<span class="w"> </span>means<span class="w"> </span>either<span class="w"> </span>making<span class="w"> </span>more<span class="w"> </span>money<span class="w"> </span>from<span class="w"> </span>sales<span class="w"> </span>or<span class="w"> </span>reducing<span class="w"> </span>the
expenses.<span class="w"> </span>Let<span class="w"> </span>me<span class="w"> </span>think<span class="w"> </span>about<span class="w"> </span>how<span class="w"> </span>I<span class="w"> </span>can<span class="w"> </span>approach<span class="w"> </span>this.
...
</code></pre></div>
<h2 id="emd_client-vlm-models">VLM models</h2>
<ol>
<li>
<p>upload image to a s3 path
<img alt="alt text" src="../sample.png" />
<div class="highlight"><pre><span></span><code>aws<span class="w"> </span>s3<span class="w"> </span>cp<span class="w"> </span>image.jpg<span class="w"> </span>s3://your-bucket/image.jpg
</code></pre></div></p>
</li>
<li>
<p>invoke the model
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w">  </span>Qwen2-VL-7B-Instruct
...
Invoking<span class="w"> </span>model<span class="w"> </span>Qwen2-VL-7B-Instruct<span class="w"> </span>with<span class="w"> </span>tag<span class="w"> </span>dev
Enter<span class="w"> </span>image<span class="w"> </span>path<span class="o">(</span><span class="nb">local</span><span class="w"> </span>or<span class="w"> </span>s3<span class="w"> </span>file<span class="o">)</span>:<span class="w"> </span>s3://your-bucket/image.jpg
Enter<span class="w"> </span>prompt:<span class="w"> </span>What<span class="err">&#39;</span>s<span class="w"> </span><span class="k">in</span><span class="w"> </span>this<span class="w"> </span>image?
...
</code></pre></div></p>
</li>
</ol>
<h3 id="emd_client-videotxt2video-models">Video(Txt2Video) models</h3>
<ol>
<li>input prompt for video generation
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w"> </span>txt2video-LTX
...
Invoking<span class="w"> </span>model<span class="w"> </span>txt2video-LTX<span class="w"> </span>with<span class="w"> </span>tag<span class="w"> </span>dev
Write<span class="w"> </span>a<span class="w"> </span>prompt,<span class="w"> </span>press<span class="w"> </span>Enter<span class="w"> </span>to<span class="w"> </span>generate<span class="w"> </span>a<span class="w"> </span>response<span class="w"> </span><span class="o">(</span>Ctrl+C<span class="w"> </span>to<span class="w"> </span>abort<span class="o">)</span>,
User:<span class="w"> </span>Two<span class="w"> </span>police<span class="w"> </span>officers<span class="w"> </span><span class="k">in</span><span class="w"> </span>dark<span class="w"> </span>blue<span class="w"> </span>uniforms<span class="w"> </span>and<span class="w"> </span>matching<span class="w"> </span>hats<span class="w"> </span>enter<span class="w"> </span>a<span class="w"> </span>dimly<span class="w"> </span>lit<span class="w"> </span>room<span class="w"> </span>through<span class="w"> </span>a<span class="w"> </span>doorway<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>left<span class="w"> </span>side<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>frame.<span class="w"> </span>The<span class="w"> </span>first<span class="w"> </span>officer,<span class="w"> </span>with<span class="w"> </span>short<span class="w"> </span>brown<span class="w"> </span>hair<span class="w"> </span>and<span class="w"> </span>a<span class="w"> </span>mustache,<span class="w"> </span>steps<span class="w"> </span>inside<span class="w"> </span>first,<span class="w"> </span>followed<span class="w"> </span>by<span class="w"> </span>his<span class="w"> </span>partner,<span class="w"> </span>who<span class="w"> </span>has<span class="w"> </span>a<span class="w"> </span>shaved<span class="w"> </span>head<span class="w"> </span>and<span class="w"> </span>a<span class="w"> </span>goatee.<span class="w"> </span>Both<span class="w"> </span>officers<span class="w"> </span>have<span class="w"> </span>serious<span class="w"> </span>expressions<span class="w"> </span>and<span class="w"> </span>maintain<span class="w"> </span>a<span class="w"> </span>steady<span class="w"> </span>pace<span class="w"> </span>as<span class="w"> </span>they<span class="w"> </span>move<span class="w"> </span>deeper<span class="w"> </span>into<span class="w"> </span>the<span class="w"> </span>room.<span class="w"> </span>The<span class="w"> </span>camera<span class="w"> </span>remains<span class="w"> </span>stationary,<span class="w"> </span>capturing<span class="w"> </span>them<span class="w"> </span>from<span class="w"> </span>a<span class="w"> </span>slightly<span class="w"> </span>low<span class="w"> </span>angle<span class="w"> </span>as<span class="w"> </span>they<span class="w"> </span>enter.<span class="w"> </span>The<span class="w"> </span>room<span class="w"> </span>has<span class="w"> </span>exposed<span class="w"> </span>brick<span class="w"> </span>walls<span class="w"> </span>and<span class="w"> </span>a<span class="w"> </span>corrugated<span class="w"> </span>metal<span class="w"> </span>ceiling,<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>barred<span class="w"> </span>window<span class="w"> </span>visible<span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>background.<span class="w"> </span>The<span class="w"> </span>lighting<span class="w"> </span>is<span class="w"> </span>low-key,<span class="w"> </span>casting<span class="w"> </span>shadows<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>officers<span class="err">&#39;</span><span class="w"> </span>faces<span class="w"> </span>and<span class="w"> </span>emphasizing<span class="w"> </span>the<span class="w"> </span>grim<span class="w"> </span>atmosphere.<span class="w"> </span>The<span class="w"> </span>scene<span class="w"> </span>appears<span class="w"> </span>to<span class="w"> </span>be<span class="w"> </span>from<span class="w"> </span>a<span class="w"> </span>film<span class="w"> </span>or<span class="w"> </span>television<span class="w"> </span>show.
...
</code></pre></div></li>
<li>download generated video from <strong>output_path</strong></li>
</ol>
<h2 id="emd_client-embedding-models">Embedding models</h2>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w"> </span>bge-base-en-v1.5
...
Invoking<span class="w"> </span>model<span class="w"> </span>bge-base-en-v1.5<span class="w"> </span>with<span class="w"> </span>tag<span class="w"> </span>dev
Enter<span class="w"> </span>the<span class="w"> </span>sentence:<span class="w"> </span>hello
...
</code></pre></div>
<h2 id="emd_client-rerank-models">Rerank models</h2>
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w"> </span>bge-reranker-v2-m3
...
Enter<span class="w"> </span>the<span class="w"> </span>text_a<span class="w"> </span><span class="o">(</span>string<span class="o">)</span>:<span class="w"> </span>What<span class="w"> </span>is<span class="w"> </span>the<span class="w"> </span>capital<span class="w"> </span>of<span class="w"> </span>France?
Enter<span class="w"> </span>the<span class="w"> </span>text_b<span class="w"> </span><span class="o">(</span>string<span class="o">)</span>:<span class="w"> </span>The<span class="w"> </span>capital<span class="w"> </span>of<span class="w"> </span>France<span class="w"> </span>is<span class="w"> </span>Paris.
...
</code></pre></div>
<h2 id="emd_client-asr-modelswhisper">ASR models(whisper)</h2>
<ol>
<li>
<p>upload audio to a s3 path
<div class="highlight"><pre><span></span><code>aws<span class="w"> </span>s3<span class="w"> </span>cp<span class="w"> </span>xx.wav<span class="w"> </span>s3://your-bucket/xx.wav
</code></pre></div></p>
</li>
<li>
<p>invoke the model
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w"> </span>whisper
...
Enter<span class="w"> </span>the<span class="w"> </span>s3<span class="w"> </span>path<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>audio<span class="w"> </span>file:<span class="w"> </span>s3://your-bucket/xx.wav
Enter<span class="w"> </span>model<span class="w"> </span><span class="o">[</span>large-v3-turbo/large-v3<span class="o">]</span>:<span class="w"> </span>large-v3-turbo
...
</code></pre></div></p>
</li>
</ol></section><section class="print-page" id="langchain_interface"><h1 id="langchain_interface-usse-langchain-interface-to-invoke-deployed-models">Usse Langchain interface to invoke deployed models</h1>
<h2 id="langchain_interface-llm-models">LLM models</h2>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmChatModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span><span class="p">,</span><span class="n">AIMessage</span><span class="p">,</span><span class="n">SystemMessage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.tools.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">StructuredTool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.utils.function_calling</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">convert_to_openai_function</span><span class="p">,</span>
    <span class="n">convert_to_openai_tool</span>
<span class="p">)</span>
<span class="n">chat_model</span> <span class="o">=</span> <span class="n">SageMakerVllmChatModel</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;Qwen2.5-7B-Instruct&quot;</span><span class="p">,</span>
    <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">chat_model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;9.11和9.9两个数字哪个更大？&quot;</span><span class="p">),</span>
    <span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">))</span>
</code></pre></div>
<h2 id="langchain_interface-vlm-models">VLM models</h2>
<ol>
<li>
<p>upload image to a s3 path
<div class="highlight"><pre><span></span><code>aws<span class="w"> </span>s3<span class="w"> </span>cp<span class="w"> </span>image.jpg<span class="w"> </span>s3://your-bucket/image.jpg
</code></pre></div></p>
</li>
<li>
<p>invoke the model
<div class="highlight"><pre><span></span><code>emd<span class="w"> </span>invoke<span class="w">  </span>Qwen2-VL-7B-Instruct
...
Invoking<span class="w"> </span>model<span class="w"> </span>Qwen2-VL-7B-Instruct<span class="w"> </span>with<span class="w"> </span>tag<span class="w"> </span>dev
Enter<span class="w"> </span>image<span class="w"> </span>path<span class="o">(</span><span class="nb">local</span><span class="w"> </span>or<span class="w"> </span>s3<span class="w"> </span>file<span class="o">)</span>:<span class="w"> </span>s3://your-bucket/image.jpg
Enter<span class="w"> </span>prompt:<span class="w"> </span>What<span class="err">&#39;</span>s<span class="w"> </span><span class="k">in</span><span class="w"> </span>this<span class="w"> </span>image?
...
</code></pre></div></p>
</li>
</ol>
<h3 id="langchain_interface-videotxt2video-models">Video(Txt2Video) models</h3>
<p>Not supported</p>
<h2 id="langchain_interface-embedding-models">Embedding models</h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmEmbeddings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmRerank</span>
<span class="n">embedding_model</span> <span class="o">=</span> <span class="n">SageMakerVllmEmbeddings</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;bge-m3&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.&#39;</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">r1</span> <span class="o">=</span> <span class="n">embedding_model</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">embedding_model</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">text</span><span class="p">]</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;embed_query: </span><span class="si">{</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;embed_documents: </span><span class="si">{</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<h2 id="langchain_interface-rerank-models">Rerank models</h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmRerank</span>
<span class="n">docs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;hi&quot;</span><span class="p">,</span><span class="s1">&#39;The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.&#39;</span><span class="p">]</span>
<span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;what is panda?&#39;</span>
<span class="n">rerank_model</span> <span class="o">=</span> <span class="n">SageMakerVllmRerank</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;bge-reranker-v2-m3&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rerank_model</span><span class="o">.</span><span class="n">rerank</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span><span class="n">documents</span><span class="o">=</span><span class="n">docs</span><span class="p">))</span>
</code></pre></div></section><section class="print-page" id="openai_compatiable"><h1 id="openai_compatiable-test-openai-compatible-interface">Test OpenAI compatible interface</h1>
<h3 id="openai_compatiable-sample-code">Sample Code</h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>
<span class="c1"># Change the api_key here to the parameter you passed in via extra-parameter</span>
<span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;your_openai_api_key&quot;</span>
<span class="k">def</span><span class="w"> </span><span class="nf">chat_with_openai_stream</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;http://ec2-54-189-171-204.us-west-2.compute.amazonaws.com:8080/v1&quot;</span>
    <span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Qwen2.5-72B-Instruct-AWQ&quot;</span><span class="p">,</span>
        <span class="c1"># model=&quot;Qwen2.5-1.5B-Instruct&quot;,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}</span>
        <span class="p">],</span>
        <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.6</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AI: &quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span>
        <span class="n">think</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="p">,</span><span class="s2">&quot;reasoning_content&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">think</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">think</span><span class="p">,</span><span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">chat_with_openai</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">(</span>
        <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
        <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;http://127.0.0.1:9000/v1&quot;</span>
    <span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;DeepSeek-R1-Distill-Qwen-1.5B&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
                  <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
        <span class="n">stream</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

<span class="c1"># Test the stream and non-stream interface</span>
<span class="n">chat_with_openai_stream</span><span class="p">(</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">)</span>
<span class="n">chat_with_openai</span><span class="p">(</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">)</span>
</code></pre></div></section><section class="print-page" id="supported_models"><table>
<thead>
<tr>
<th style="text-align: left;">ModeId</th>
<th style="text-align: left;">ModelSeries</th>
<th style="text-align: left;">ModelType</th>
<th style="text-align: left;">Supported Engines</th>
<th style="text-align: left;">Supported Instances</th>
<th style="text-align: left;">Supported Services</th>
<th style="text-align: left;">Support China Region</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">glm-4-9b-chat</td>
<td style="text-align: left;">glm4</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">internlm2_5-20b-chat-4bit-awq</td>
<td style="text-align: left;">internlm2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">internlm2_5-20b-chat</td>
<td style="text-align: left;">internlm2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">internlm2_5-7b-chat</td>
<td style="text-align: left;">internlm2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">internlm2_5-7b-chat-4bit</td>
<td style="text-align: left;">internlm2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">internlm2_5-1_8b-chat</td>
<td style="text-align: left;">internlm2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-7B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,tgi,tgi</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,inf2.8xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-72B-Instruct-AWQ</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,tgi</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge,inf2.24xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-72B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-72B-Instruct-AWQ-128k</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-32B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-0.5B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,tgi</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge,inf2.8xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-1.5B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-3B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-14B-Instruct-AWQ</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge,g4dn.2xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-14B-Instruct</td>
<td style="text-align: left;">qwen2.5</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">QwQ-32B-Preview</td>
<td style="text-align: left;">qwen reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">QwQ-32B</td>
<td style="text-align: left;">qwen reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">llama-3.3-70b-instruct-awq</td>
<td style="text-align: left;">llama</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">tgi</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-32B</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,tgi</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-14B</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-7B</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-1.5B</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-1.5B_ollama</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">ollama</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-1.5B-GGUF</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">llama.cpp</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Qwen-32B-GGUF</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">llama.cpp</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-R1-Distill-Llama-8B</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">deepseek-r1-distill-llama-70b-awq</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,tgi</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">deepseek-r1-671b-1.58bit_ollama</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">ollama</td>
<td style="text-align: left;">g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">deepseek-r1-671b-1.58bit_gguf</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">llama.cpp,ktransformers</td>
<td style="text-align: left;">g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,g6.8xlarge,g6.12xlarge,g6.16xlarge,g6.24xlarge,g6.48xlarge,g6e.4xlarge,g6e.8xlarge,g6e.12xlarge,g6e.16xlarge,g6e.24xlarge,g6e.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">deepseek-r1-671b-2.51bit_gguf</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">ktransformers</td>
<td style="text-align: left;">g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,g6.12xlarge,g6.16xlarge,g6.24xlarge,g6.48xlarge,g6e.8xlarge,g6e.12xlarge,g6e.16xlarge,g6e.24xlarge,g6e.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">deepseek-r1-671b-4bit_gguf</td>
<td style="text-align: left;">deepseek reasoning model</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">ktransformers</td>
<td style="text-align: left;">g5.24xlarge,g5.48xlarge,g6.24xlarge,g6.48xlarge,g6e.16xlarge,g6e.24xlarge,g6e.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">deepseek-v3-UD-IQ1_M_ollama</td>
<td style="text-align: left;">deepseek v3</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">ollama</td>
<td style="text-align: left;">g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">Baichuan-M1-14B-Instruct</td>
<td style="text-align: left;">baichuan</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,huggingface</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">ReaderLM-v2</td>
<td style="text-align: left;">jina</td>
<td style="text-align: left;">llm</td>
<td style="text-align: left;">vllm,tgi</td>
<td style="text-align: left;">g4dn.2xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge,inf2.8xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2-VL-72B-Instruct-AWQ</td>
<td style="text-align: left;">qwen2vl</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-VL-72B-Instruct-AWQ</td>
<td style="text-align: left;">qwen2vl</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2.5-VL-32B-Instruct</td>
<td style="text-align: left;">qwen2vl</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">QVQ-72B-Preview-AWQ</td>
<td style="text-align: left;">qwen reasoning model</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">Qwen2-VL-7B-Instruct</td>
<td style="text-align: left;">qwen2vl</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.12xlarge,g5.16xlarge,g5.24xlarge,g5.48xlarge,g6e.2xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">InternVL2_5-78B-AWQ</td>
<td style="text-align: left;">internvl2.5</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">lmdeploy</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">gemma-3-4b-it</td>
<td style="text-align: left;">gemma3</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">gemma-3-12b-it</td>
<td style="text-align: left;">gemma3</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">gemma-3-27b-it</td>
<td style="text-align: left;">gemma3</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">Mistral-Small-3.1-24B-Instruct-2503</td>
<td style="text-align: left;">mistral</td>
<td style="text-align: left;">vlm</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.12xlarge,g5.24xlarge,g5.48xlarge</td>
<td style="text-align: left;">sagemaker_realtime,sagemaker_async,ecs</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">txt2video-LTX</td>
<td style="text-align: left;">comfyui</td>
<td style="text-align: left;">video</td>
<td style="text-align: left;">comfyui</td>
<td style="text-align: left;">g5.4xlarge,g5.8xlarge,g6e.2xlarge</td>
<td style="text-align: left;">sagemaker_async</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">whisper</td>
<td style="text-align: left;">whisper</td>
<td style="text-align: left;">whisper</td>
<td style="text-align: left;">huggingface</td>
<td style="text-align: left;">g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_async</td>
<td style="text-align: left;">❎</td>
</tr>
<tr>
<td style="text-align: left;">bce-embedding-base_v1</td>
<td style="text-align: left;">bce</td>
<td style="text-align: left;">embedding</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g4dn.2xlarge,g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">bge-base-en-v1.5</td>
<td style="text-align: left;">bge</td>
<td style="text-align: left;">embedding</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">bge-m3</td>
<td style="text-align: left;">bge</td>
<td style="text-align: left;">embedding</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">jina-embeddings-v3</td>
<td style="text-align: left;">jina</td>
<td style="text-align: left;">embedding</td>
<td style="text-align: left;">huggingface</td>
<td style="text-align: left;">g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">bge-reranker-v2-m3</td>
<td style="text-align: left;">bge</td>
<td style="text-align: left;">rerank</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g4dn.2xlarge,g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">bge-reranker-large</td>
<td style="text-align: left;">bge</td>
<td style="text-align: left;">rerank</td>
<td style="text-align: left;">vllm</td>
<td style="text-align: left;">g4dn.2xlarge,g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
<tr>
<td style="text-align: left;">jina-reranker-v2-base-multilingual</td>
<td style="text-align: left;">jina</td>
<td style="text-align: left;">rerank</td>
<td style="text-align: left;">huggingface</td>
<td style="text-align: left;">g5.xlarge,g5.2xlarge,g5.4xlarge,g5.8xlarge,g5.16xlarge</td>
<td style="text-align: left;">sagemaker_realtime,ecs</td>
<td style="text-align: left;">✅</td>
</tr>
</tbody>
</table></section></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "/aws-samples/easy-model-deployer/", "features": ["navigation.tabs"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": "develop"}</script>
    
    
      <script src="../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="../js/print-site.js"></script>
      
    
  </body>
</html>