<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://github.com/aws-samples/easy-model-deployer/sdk_integration.html" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>LangChain Integration - Easy Model Deployer</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="css/print-site-enum-headings1.css" rel="stylesheet" />
        <link href="css/print-site-enum-headings2.css" rel="stylesheet" />
        <link href="css/print-site-enum-headings3.css" rel="stylesheet" />
        <link href="css/print-site-enum-headings4.css" rel="stylesheet" />
        <link href="css/print-site-enum-headings5.css" rel="stylesheet" />
        <link href="css/print-site-enum-headings6.css" rel="stylesheet" />
        <link href="css/print-site.css" rel="stylesheet" />
        <link href="css/print-site-readthedocs.css" rel="stylesheet" />
        <link href="custom.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "LangChain Integration";
        var mkdocs_page_input_path = "sdk_integration.md";
        var mkdocs_page_url = "/aws-samples/easy-model-deployer/sdk_integration.html";
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> Easy Model Deployer
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="installation.html">Quick Start</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="model-generator.html">Supported Models</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="best_deployment_practices.html">Best Deployment Practices</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="commands.html">CLI Commands</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="sdk_api.html">SDK API</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="local_deployment.html">Local Deployment</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">LangChain Integration</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#llm-models">LLM Models</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#function-calling-with-langchain">Function Calling with LangChain</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#embedding-models">Embedding Models</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#reranking-models">Reranking Models</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#vision-models-vlm">Vision Models (VLM)</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="swift_chat_integration.html">SwiftChat Integration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="dify_integration.html">Dify Integration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="langflow_integration.html">LangFlow Integration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="flowise_integration.html">Flowise Integration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="ollama_integration.html">Ollama Integration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="nextchat_integration.html">NextChat Integration</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">Easy Model Deployer</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">LangChain Integration</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/aws-samples/easy-model-deployer/edit/master/docs/sdk_integration.md">Edit on aws-samples/easy-model-deployer</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="langchain-integration">LangChain Integration</h1>
<p>This guide covers how to integrate with deployed models using the LangChain framework.</p>
<h2 id="llm-models">LLM Models</h2>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmChatModel</span>
</span><span id="__span-0-2"><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
</span><span id="__span-0-3"><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span><span class="p">,</span> <span class="n">AIMessage</span><span class="p">,</span> <span class="n">SystemMessage</span>
</span><span id="__span-0-4">
</span><span id="__span-0-5"><span class="c1"># Initialize the chat model</span>
</span><span id="__span-0-6"><span class="n">chat_model</span> <span class="o">=</span> <span class="n">SageMakerVllmChatModel</span><span class="p">(</span>
</span><span id="__span-0-7">    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;Qwen2.5-7B-Instruct&quot;</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-0-9">        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span id="__span-0-10">    <span class="p">}</span>
</span><span id="__span-0-11"><span class="p">)</span>
</span><span id="__span-0-12">
</span><span id="__span-0-13"><span class="c1"># Create a simple chain</span>
</span><span id="__span-0-14"><span class="n">chain</span> <span class="o">=</span> <span class="n">chat_model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
</span><span id="__span-0-15">
</span><span id="__span-0-16"><span class="c1"># Define messages</span>
</span><span id="__span-0-17"><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-18">    <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">),</span>
</span><span id="__span-0-19"><span class="p">]</span>
</span><span id="__span-0-20">
</span><span id="__span-0-21"><span class="c1"># Invoke the chain</span>
</span><span id="__span-0-22"><span class="n">response</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
</span><span id="__span-0-23"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span></code></pre></div>
<h2 id="function-calling-with-langchain">Function Calling with LangChain</h2>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.tools.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">StructuredTool</span>
</span><span id="__span-1-2"><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.utils.function_calling</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="__span-1-3">    <span class="n">convert_to_openai_function</span><span class="p">,</span>
</span><span id="__span-1-4">    <span class="n">convert_to_openai_tool</span>
</span><span id="__span-1-5"><span class="p">)</span>
</span><span id="__span-1-6">
</span><span id="__span-1-7"><span class="c1"># Define a function</span>
</span><span id="__span-1-8"><span class="k">def</span><span class="w"> </span><span class="nf">get_weather</span><span class="p">(</span><span class="n">location</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">unit</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;celsius&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="__span-1-9"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the current weather in a given location&quot;&quot;&quot;</span>
</span><span id="__span-1-10">    <span class="c1"># This would call a weather API in a real application</span>
</span><span id="__span-1-11">    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;The weather in </span><span class="si">{</span><span class="n">location</span><span class="si">}</span><span class="s2"> is sunny and 25 degrees </span><span class="si">{</span><span class="n">unit</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="__span-1-12">
</span><span id="__span-1-13"><span class="c1"># Create a tool</span>
</span><span id="__span-1-14"><span class="n">weather_tool</span> <span class="o">=</span> <span class="n">StructuredTool</span><span class="o">.</span><span class="n">from_function</span><span class="p">(</span><span class="n">get_weather</span><span class="p">)</span>
</span><span id="__span-1-15">
</span><span id="__span-1-16"><span class="c1"># Convert to OpenAI tool format</span>
</span><span id="__span-1-17"><span class="n">openai_tool</span> <span class="o">=</span> <span class="n">convert_to_openai_tool</span><span class="p">(</span><span class="n">weather_tool</span><span class="p">)</span>
</span><span id="__span-1-18">
</span><span id="__span-1-19"><span class="c1"># Initialize the model with tools</span>
</span><span id="__span-1-20"><span class="n">chat_model</span> <span class="o">=</span> <span class="n">SageMakerVllmChatModel</span><span class="p">(</span>
</span><span id="__span-1-21">    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;Qwen2.5-7B-Instruct&quot;</span><span class="p">,</span>
</span><span id="__span-1-22">    <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-1-23">        <span class="s2">&quot;tools&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">openai_tool</span><span class="p">],</span>
</span><span id="__span-1-24">        <span class="s2">&quot;tool_choice&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="__span-1-25">    <span class="p">}</span>
</span><span id="__span-1-26"><span class="p">)</span>
</span><span id="__span-1-27">
</span><span id="__span-1-28"><span class="c1"># Invoke with a query that should trigger tool use</span>
</span><span id="__span-1-29"><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-1-30">    <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;What&#39;s the weather like in Paris?&quot;</span><span class="p">)</span>
</span><span id="__span-1-31"><span class="p">]</span>
</span><span id="__span-1-32">
</span><span id="__span-1-33"><span class="n">response</span> <span class="o">=</span> <span class="n">chat_model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
</span><span id="__span-1-34"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span></code></pre></div>
<h2 id="embedding-models">Embedding Models</h2>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="__span-2-2"><span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmEmbeddings</span>
</span><span id="__span-2-3">
</span><span id="__span-2-4"><span class="c1"># Initialize the embedding model</span>
</span><span id="__span-2-5"><span class="n">embedding_model</span> <span class="o">=</span> <span class="n">SageMakerVllmEmbeddings</span><span class="p">(</span>
</span><span id="__span-2-6">    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;bge-m3&quot;</span><span class="p">,</span>
</span><span id="__span-2-7"><span class="p">)</span>
</span><span id="__span-2-8">
</span><span id="__span-2-9"><span class="c1"># Get embeddings for a single text</span>
</span><span id="__span-2-10"><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.&#39;</span>
</span><span id="__span-2-11"><span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding_model</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span id="__span-2-12">
</span><span id="__span-2-13"><span class="c1"># Get embeddings for multiple documents</span>
</span><span id="__span-2-14"><span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># 10 copies of the same text for demonstration</span>
</span><span id="__span-2-15"><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embedding_model</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</span><span id="__span-2-16">
</span><span id="__span-2-17"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Single embedding dimension: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-2-18"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of document embeddings: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h2 id="reranking-models">Reranking Models</h2>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><span class="kn">from</span><span class="w"> </span><span class="nn">emd.integrations.langchain_clients</span><span class="w"> </span><span class="kn">import</span> <span class="n">SageMakerVllmRerank</span>
</span><span id="__span-3-2">
</span><span id="__span-3-3"><span class="c1"># Initialize the reranker</span>
</span><span id="__span-3-4"><span class="n">rerank_model</span> <span class="o">=</span> <span class="n">SageMakerVllmRerank</span><span class="p">(</span>
</span><span id="__span-3-5">    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;bge-reranker-v2-m3&quot;</span>
</span><span id="__span-3-6"><span class="p">)</span>
</span><span id="__span-3-7">
</span><span id="__span-3-8"><span class="c1"># Define documents and query</span>
</span><span id="__span-3-9"><span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-3-10">    <span class="s2">&quot;The giant panda is a bear species endemic to China.&quot;</span><span class="p">,</span>
</span><span id="__span-3-11">    <span class="s2">&quot;Paris is the capital of France.&quot;</span><span class="p">,</span>
</span><span id="__span-3-12">    <span class="s2">&quot;Machine learning is a subset of artificial intelligence.&quot;</span>
</span><span id="__span-3-13"><span class="p">]</span>
</span><span id="__span-3-14"><span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;What is a panda?&#39;</span>
</span><span id="__span-3-15">
</span><span id="__span-3-16"><span class="c1"># Rerank documents based on relevance to the query</span>
</span><span id="__span-3-17"><span class="n">results</span> <span class="o">=</span> <span class="n">rerank_model</span><span class="o">.</span><span class="n">rerank</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">documents</span><span class="o">=</span><span class="n">docs</span><span class="p">)</span>
</span><span id="__span-3-18">
</span><span id="__span-3-19"><span class="c1"># Print results</span>
</span><span id="__span-3-20"><span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
</span><span id="__span-3-21">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Document: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">document</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-3-22">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">relevance_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-3-23">    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h2 id="vision-models-vlm">Vision Models (VLM)</h2>
<p>For vision models, you can use the EMD CLI to invoke them:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><span class="c1"># Upload an image to S3</span>
</span><span id="__span-4-2">aws<span class="w"> </span>s3<span class="w"> </span>cp<span class="w"> </span>image.jpg<span class="w"> </span>s3://your-bucket/image.jpg
</span><span id="__span-4-3">
</span><span id="__span-4-4"><span class="c1"># Invoke the vision model</span>
</span><span id="__span-4-5">emd<span class="w"> </span>invoke<span class="w"> </span>Qwen2-VL-7B-Instruct
</span></code></pre></div>
<p>When prompted:
- Enter the S3 path to your image: <code>s3://your-bucket/image.jpg</code>
- Enter your prompt: <code>What's in this image?</code></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="architecture.html" class="btn btn-neutral float-left" title="Architecture"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="swift_chat_integration.html" class="btn btn-neutral float-right" title="SwiftChat Integration">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/aws-samples/easy-model-deployer/" class="fa fa-code-fork" style="color: #fcfcfc"> aws-samples/easy-model-deployer</a>
        </span>
    
    
      <span><a href="architecture.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="swift_chat_integration.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="js/print-site.js"></script>
      <script src="copy-button.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
